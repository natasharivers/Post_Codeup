{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a data series with limit 30\n",
    "dataseries=pd.Series(np.random.rand(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.643971\n",
       "1    0.440669\n",
       "2    0.414223\n",
       "3    0.240424\n",
       "4    0.727840\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at first 5\n",
    "dataseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.533554</td>\n",
       "      <td>-0.104067</td>\n",
       "      <td>-0.477346</td>\n",
       "      <td>-0.657351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.698157</td>\n",
       "      <td>0.431270</td>\n",
       "      <td>0.882627</td>\n",
       "      <td>-0.320914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006240</td>\n",
       "      <td>0.116799</td>\n",
       "      <td>1.422803</td>\n",
       "      <td>-0.523466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.425009</td>\n",
       "      <td>-0.228157</td>\n",
       "      <td>-0.449240</td>\n",
       "      <td>-0.283418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.500307</td>\n",
       "      <td>0.762716</td>\n",
       "      <td>-0.795830</td>\n",
       "      <td>0.098143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          T         A         R         S\n",
       "0 -0.533554 -0.104067 -0.477346 -0.657351\n",
       "1 -0.698157  0.431270  0.882627 -0.320914\n",
       "2  0.006240  0.116799  1.422803 -0.523466\n",
       "3  1.425009 -0.228157 -0.449240 -0.283418\n",
       "4 -0.500307  0.762716 -0.795830  0.098143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe\n",
    "## 4 columns, 50 rows, name columns\n",
    "datawithfeatures = pd.DataFrame(np.random.randn(50,4), columns=list('TARS'))\n",
    "\n",
    "#take a look at the first 5 rows\n",
    "datawithfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    0.872216\n",
       "27    0.499499\n",
       "20    0.542493\n",
       "7     0.163482\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create 4 samples\n",
    "sampleseries = dataseries.sample(n=4)\n",
    "\n",
    "#look at the sample\n",
    "sampleseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    0.872216\n",
       "26    0.872216\n",
       "24    0.793023\n",
       "8     0.350108\n",
       "15    0.339541\n",
       "8     0.350108\n",
       "18    0.495007\n",
       "23    0.909471\n",
       "8     0.350108\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#30% of data set\n",
    "sampleseries1= dataseries.sample(frac=0.3, replace=True)\n",
    "\n",
    "#look at sample series 1\n",
    "sampleseries1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA\n",
    "- reducing dimensionality with Principle Component Analysis (PCA)\n",
    "- one of the most popular unsupervised transformation techniques\n",
    "    - facilitates the task of reducing dimensions\n",
    "    - provides logical set of data on which we can apply machine learning algorithms\n",
    "- finds direction of max variance and high dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy:\n",
    "- standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import iris dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save iris dataset to X variable\n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "#get shape of dataset\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "X_std=StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build covarient matrix\n",
    "covmat = np.cov(X_std.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00671141 -0.11835884  0.87760447  0.82343066]\n",
      " [-0.11835884  1.00671141 -0.43131554 -0.36858315]\n",
      " [ 0.87760447 -0.43131554  1.00671141  0.96932762]\n",
      " [ 0.82343066 -0.36858315  0.96932762  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "#take a look at covarient matrix\n",
    "print(covmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform eigan decomposition\n",
    "eigval, eigvec = np.linalg.eig(covmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52106591 -0.37741762 -0.71956635  0.26128628]\n",
      " [-0.26934744 -0.92329566  0.24438178 -0.12350962]\n",
      " [ 0.5804131  -0.02449161  0.14212637 -0.80144925]\n",
      " [ 0.56485654 -0.06694199  0.63427274  0.52359713]]\n"
     ]
    }
   ],
   "source": [
    "#look at eigan vector\n",
    "print(eigvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.93808505 0.9201649  0.14774182 0.02085386]\n"
     ]
    }
   ],
   "source": [
    "#look at eigan value\n",
    "print(eigval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72.96244541329985, 22.8507617867018, 3.668921889282875, 0.5178709107154843]\n"
     ]
    }
   ],
   "source": [
    "#sort eigan values in decreasing order\n",
    "eigpairs = [(np.abs(eigval[i]), eigvec[:,i]) for i in range\n",
    "            (len(eigval))]\n",
    "\n",
    "#find total by adding eigan values together\n",
    "total= sum(eigval)\n",
    "\n",
    "#cummulative variance\n",
    "varexp=[(i/total)*100 for i in sorted(eigval, reverse=True)]\n",
    "\n",
    "#take a look at result\n",
    "print(varexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
